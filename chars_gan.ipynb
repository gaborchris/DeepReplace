{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "chars_gan",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gaborchris/DeepReplace/blob/master/chars_gan.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hOuYg9rkmc1b",
        "colab_type": "code",
        "outputId": "593587c9-9e95-4993-e2cc-5307d0200e3e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "\n",
        "try:\n",
        "  from google.colab import files\n",
        "except Exception:\n",
        "  print(Exception)\n",
        "  pass\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "import glob\n",
        "import imageio\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import PIL\n",
        "from tensorflow.keras import layers\n",
        "import time\n",
        "import pathlib"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mF40fEZi4hb-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 64\n",
        "NOISE_DIM = 100\n",
        "\n",
        "num_to_char = {}\n",
        "alphabet = 'abcdefghijklmnopqrstuvwxyz'\n",
        "for i in range(0, 10):\n",
        "    num_to_char[i] = str(i)\n",
        "for i in range(0, 26):\n",
        "    num_to_char[i+10] = alphabet[i].upper()\n",
        "for i in range(0, 26):\n",
        "    num_to_char[i+10+26] = alphabet[i].lower()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zAS3PZw_4pIc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_generator_model(n_classes=10):\n",
        "    # Create class embedding channel\n",
        "    input_label = tf.keras.layers.Input(shape=(1,))\n",
        "    label_embedding = tf.keras.layers.Embedding(n_classes, 50)(input_label)\n",
        "    upscaling = tf.keras.layers.Dense(7*7*1)(label_embedding)\n",
        "    upscaling = tf.keras.layers.Reshape((7, 7, 1))(upscaling)\n",
        "\n",
        "    # create seed encoding network\n",
        "    seed_input = tf.keras.layers.Input(shape=(NOISE_DIM,))\n",
        "    seed_fc = tf.keras.layers.Dense(7*7*256, use_bias=False)(seed_input)\n",
        "    seed_fc = tf.keras.layers.BatchNormalization()(seed_fc)\n",
        "    seed_fc = tf.keras.layers.LeakyReLU()(seed_fc)\n",
        "    seed_fc = tf.keras.layers.Reshape((7, 7, 256))(seed_fc)\n",
        "\n",
        "    # merge embedding with seed encoder\n",
        "    merge = tf.keras.layers.Concatenate()([seed_fc, upscaling])\n",
        "    assert tuple(merge.shape) == (None, 7, 7, 256+1)\n",
        "\n",
        "    x = layers.Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', use_bias=False)(merge)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.LeakyReLU()(x)\n",
        "    assert tuple(x.shape) == (None, 7, 7, 128)\n",
        "\n",
        "    x = layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.LeakyReLU()(x)\n",
        "    assert tuple(x.shape) == (None, 14, 14, 64)\n",
        "\n",
        "    # TODO tanh function with output between [-1, 1]\n",
        "    output = layers.Conv2DTranspose(3, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh')(x)\n",
        "    model = tf.keras.Model([seed_input, input_label], output)\n",
        "    assert model.output_shape == (None, 28, 28, 3)\n",
        "\n",
        "    return model\n",
        "\n",
        "def make_discriminator_model(n_classes=10):\n",
        "    # Create a class embedding\n",
        "    input_label = tf.keras.layers.Input(shape=(1,))\n",
        "    label_embedding = tf.keras.layers.Embedding(n_classes, 50)(input_label)\n",
        "    upscaling = tf.keras.layers.Dense(28*28)(label_embedding)\n",
        "    upscaling = tf.keras.layers.Reshape((28, 28, 1))(upscaling)\n",
        "\n",
        "    # merge image with class embedding\n",
        "    input_image = tf.keras.layers.Input(shape=(28, 28, 3))\n",
        "    merge = tf.keras.layers.Concatenate()([input_image, upscaling])\n",
        "\n",
        "    # define classification architecture\n",
        "    x = tf.keras.layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same')(merge)\n",
        "    x = tf.keras.layers.LeakyReLU()(x)\n",
        "    x = tf.keras.layers.Dropout(0.3)(x)\n",
        "\n",
        "    x = layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same')(x)\n",
        "    x = layers.LeakyReLU()(x)\n",
        "    x = layers.Dropout(0.3)(x)\n",
        "\n",
        "    x = layers.Flatten()(x)\n",
        "    output = layers.Dense(1)(x)\n",
        "    model = tf.keras.Model([input_image, input_label], output)\n",
        "\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_V1zofMn40y0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "def discriminator_loss(real_output, fake_output):\n",
        "    cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
        "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
        "    total_loss = real_loss + fake_loss\n",
        "    return total_loss\n",
        "\n",
        "\n",
        "def generator_loss(predictions):\n",
        "    cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "    return cross_entropy(tf.ones_like(predictions), predictions)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Z3WdIEg4ZCs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_and_save_images(model, epoch, test_input, test_labels):\n",
        "    predictions = model([test_input, test_labels], training=False)\n",
        "\n",
        "    for i in range(predictions.shape[0]):\n",
        "        plt.subplot(4, 4, i + 1)\n",
        "        plt.imshow(predictions[i, :, :, :] / 2. + 0.5)\n",
        "        plt.xticks([])\n",
        "        plt.yticks([])\n",
        "        plt.xlabel(num_to_char[test_labels[i][0]])\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))\n",
        "    plt.close()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "slRA1OBoFtj7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def image_norm(img):\n",
        "  return (img - 127.5) / 127.5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sOW2jrDmnNv7",
        "colab_type": "code",
        "outputId": "c95a2318-ae0c-4131-f51a-d1a6e079365b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# Get ground truth data\n",
        "data_dir = tf.keras.utils.get_file('English',\n",
        "                                    origin='http://www.ee.surrey.ac.uk/CVSSP/demos/chars74k/EnglishImg.tgz',\n",
        "                                    untar=True, extract=True)\n",
        "data_dir = pathlib.Path(data_dir)\n",
        "image_path = os.path.join(data_dir, \"Img/GoodImg/Bmp\")\n",
        "\n",
        "image_generator = tf.keras.preprocessing.image.ImageDataGenerator(preprocessing_function=lambda img: (img - 127.5) / 127.5)\n",
        "image_ground_truth = image_generator.flow_from_directory(image_path, target_size=(28, 28),\n",
        "                                                          batch_size=BATCH_SIZE,\n",
        "                                                          class_mode='sparse')\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from http://www.ee.surrey.ac.uk/CVSSP/demos/chars74k/EnglishImg.tgz\n",
            "133980160/133975105 [==============================] - 1s 0us/step\n",
            "Found 7705 images belonging to 62 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PmtYEq344QHP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define Model\n",
        "num_classes = 62\n",
        "\n",
        "generator = make_generator_model(n_classes=num_classes)\n",
        "generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
        "discriminator = make_discriminator_model(n_classes=num_classes)\n",
        "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
        "\n",
        "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
        "                                  discriminator_optimizer=discriminator_optimizer,\n",
        "                                  generator=generator,\n",
        "                                  discriminator=discriminator)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CVVyZ1Sb4TO9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_examples_to_generate = 16\n",
        "seed = tf.random.normal([num_examples_to_generate, NOISE_DIM])\n",
        "seed_labels = np.random.randint(0, num_classes, num_examples_to_generate).reshape((-1, 1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zPyic9uYo5kD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define training procedure\n",
        "@tf.function\n",
        "def train_step(images, ground_truth_labels):\n",
        "    noise = tf.random.normal([BATCH_SIZE, NOISE_DIM])\n",
        "    random_labels = np.random.randint(0, num_classes, BATCH_SIZE).reshape((-1, 1))\n",
        "\n",
        "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "        fakes = generator([noise, random_labels], training=True)\n",
        "        ground_truth_preds = discriminator([images, ground_truth_labels], training=True)\n",
        "        fake_preds = discriminator([fakes, random_labels], training=True)\n",
        "\n",
        "        gen_loss = generator_loss(fake_preds)\n",
        "        disc_loss = discriminator_loss(real_output=ground_truth_preds, fake_output=fake_preds)\n",
        "\n",
        "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
        "\n",
        "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
        "\n",
        "def train(dataset, epochs, ckpt_prefix):\n",
        "    print(\"Starting training\")\n",
        "    for epoch in range(epochs):\n",
        "        start = time.time()\n",
        "        i = 0\n",
        "        for (image_batch, labels_batch) in dataset:\n",
        "            train_step(image_batch, labels_batch)\n",
        "            i += 1\n",
        "            if i > len(dataset):\n",
        "              break\n",
        "              \n",
        "        if (epoch + 1) % 5 == 0:\n",
        "            generate_and_save_images(generator, epoch+1, seed, seed_labels)  \n",
        "            checkpoint.save(file_prefix=ckpt_prefix)\n",
        "            try:\n",
        "                files.download('image_at_epoch_{:04d}.png'.format(epoch+1))\n",
        "            except Exception as e:\n",
        "                print(e)\n",
        "                    \n",
        "        print('Time for epoch {} is {} sec'.format(epoch+1, time.time()-start))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qbrs4IFm7xzm",
        "colab_type": "code",
        "outputId": "b83c0ac5-ca72-4019-bb54-8ce323dd47c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ml85TFUa4-Qh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "checkpoint_dir = '/content/drive/My Drive/char_gan_ckpts/'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qLbSUSv19QRB",
        "colab_type": "code",
        "outputId": "d6164608-cb22-4820-ea10-c461d7486fdf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "status = checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))\n",
        "\n",
        "# Setup repeated predictions\n",
        "fakes = generator([seed, seed_labels], training=False)\n",
        "generate_and_save_images(generator, 0, seed, seed_labels)\n",
        "\n",
        "train(image_ground_truth, epochs=1000, ckpt_prefix=checkpoint_prefix)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting training\n",
            "Time for epoch 1 is 16.95930051803589 sec\n",
            "Time for epoch 2 is 12.226705551147461 sec\n",
            "Time for epoch 3 is 12.187940120697021 sec\n",
            "Time for epoch 4 is 12.1890549659729 sec\n",
            "TypeError: Failed to fetch\n",
            "Time for epoch 5 is 17.16190195083618 sec\n",
            "Time for epoch 6 is 12.282199144363403 sec\n",
            "Time for epoch 7 is 12.259150981903076 sec\n",
            "Time for epoch 8 is 12.183095932006836 sec\n",
            "Time for epoch 9 is 12.138511419296265 sec\n",
            "TypeError: Failed to fetch\n",
            "Time for epoch 10 is 17.349053859710693 sec\n",
            "Time for epoch 11 is 12.220382452011108 sec\n",
            "Time for epoch 12 is 12.138003826141357 sec\n",
            "Time for epoch 13 is 12.160072326660156 sec\n",
            "Time for epoch 14 is 12.152195930480957 sec\n",
            "TypeError: Failed to fetch\n",
            "Time for epoch 15 is 17.204927444458008 sec\n",
            "Time for epoch 16 is 12.338332653045654 sec\n",
            "Time for epoch 17 is 12.28376841545105 sec\n",
            "Time for epoch 18 is 12.251060724258423 sec\n",
            "Time for epoch 19 is 12.243784427642822 sec\n",
            "TypeError: Failed to fetch\n",
            "Time for epoch 20 is 17.147499084472656 sec\n",
            "Time for epoch 21 is 12.201660633087158 sec\n",
            "Time for epoch 22 is 12.294819355010986 sec\n",
            "Time for epoch 23 is 12.08705997467041 sec\n",
            "Time for epoch 24 is 12.14175534248352 sec\n",
            "TypeError: Failed to fetch\n",
            "Time for epoch 25 is 16.94164204597473 sec\n",
            "Time for epoch 26 is 12.263026237487793 sec\n",
            "Time for epoch 27 is 12.090834617614746 sec\n",
            "Time for epoch 28 is 12.020885229110718 sec\n",
            "Time for epoch 29 is 12.031257390975952 sec\n",
            "TypeError: Failed to fetch\n",
            "Time for epoch 30 is 17.037683963775635 sec\n",
            "Time for epoch 31 is 12.052458047866821 sec\n",
            "Time for epoch 32 is 12.04171872138977 sec\n",
            "Time for epoch 33 is 12.014405250549316 sec\n",
            "Time for epoch 34 is 11.933260917663574 sec\n",
            "TypeError: Failed to fetch\n",
            "Time for epoch 35 is 16.972420692443848 sec\n",
            "Time for epoch 36 is 12.115909337997437 sec\n",
            "Time for epoch 37 is 12.062047004699707 sec\n",
            "Time for epoch 38 is 12.0743088722229 sec\n",
            "Time for epoch 39 is 12.11384391784668 sec\n",
            "TypeError: Failed to fetch\n",
            "Time for epoch 40 is 17.549888849258423 sec\n",
            "Time for epoch 41 is 12.051935195922852 sec\n",
            "Time for epoch 42 is 12.034363985061646 sec\n",
            "Time for epoch 43 is 12.216134548187256 sec\n",
            "Time for epoch 44 is 12.084798336029053 sec\n",
            "TypeError: Failed to fetch\n",
            "Time for epoch 45 is 17.090202808380127 sec\n",
            "Time for epoch 46 is 12.213136434555054 sec\n",
            "Time for epoch 47 is 12.121025800704956 sec\n",
            "Time for epoch 48 is 12.027048587799072 sec\n",
            "Time for epoch 49 is 12.13687014579773 sec\n",
            "TypeError: Failed to fetch\n",
            "Time for epoch 50 is 17.10407328605652 sec\n",
            "Time for epoch 51 is 12.195721626281738 sec\n",
            "Time for epoch 52 is 12.069889783859253 sec\n",
            "Time for epoch 53 is 12.161119222640991 sec\n",
            "Time for epoch 54 is 12.04505968093872 sec\n",
            "TypeError: Failed to fetch\n",
            "Time for epoch 55 is 17.28681206703186 sec\n",
            "Time for epoch 56 is 12.129528284072876 sec\n",
            "Time for epoch 57 is 12.187220811843872 sec\n",
            "Time for epoch 58 is 12.204659700393677 sec\n",
            "Time for epoch 59 is 12.072360038757324 sec\n",
            "TypeError: Failed to fetch\n",
            "Time for epoch 60 is 17.17281174659729 sec\n",
            "Time for epoch 61 is 12.194104671478271 sec\n",
            "Time for epoch 62 is 12.090988397598267 sec\n",
            "Time for epoch 63 is 12.323943138122559 sec\n",
            "Time for epoch 64 is 12.059976577758789 sec\n",
            "TypeError: Failed to fetch\n",
            "Time for epoch 65 is 17.125494480133057 sec\n",
            "Time for epoch 66 is 12.22511601448059 sec\n",
            "Time for epoch 67 is 12.116255521774292 sec\n",
            "Time for epoch 68 is 12.148736476898193 sec\n",
            "Time for epoch 69 is 12.282091617584229 sec\n",
            "TypeError: Failed to fetch\n",
            "Time for epoch 70 is 17.099756240844727 sec\n",
            "Time for epoch 71 is 12.252326011657715 sec\n",
            "Time for epoch 72 is 12.154585123062134 sec\n",
            "Time for epoch 73 is 12.111032724380493 sec\n",
            "Time for epoch 74 is 12.175636291503906 sec\n",
            "TypeError: Failed to fetch\n",
            "Time for epoch 75 is 17.060545444488525 sec\n",
            "Time for epoch 76 is 12.26312780380249 sec\n",
            "Time for epoch 77 is 12.262356519699097 sec\n",
            "Time for epoch 78 is 12.128015756607056 sec\n",
            "Time for epoch 79 is 12.231650352478027 sec\n",
            "TypeError: Failed to fetch\n",
            "Time for epoch 80 is 17.393555402755737 sec\n",
            "Time for epoch 81 is 12.250986099243164 sec\n",
            "Time for epoch 82 is 12.093294858932495 sec\n",
            "Time for epoch 83 is 12.047375917434692 sec\n",
            "Time for epoch 84 is 12.10635256767273 sec\n",
            "TypeError: Failed to fetch\n",
            "Time for epoch 85 is 17.275490283966064 sec\n",
            "Time for epoch 86 is 12.367969036102295 sec\n",
            "Time for epoch 87 is 12.1587975025177 sec\n",
            "Time for epoch 88 is 12.206586599349976 sec\n",
            "Time for epoch 89 is 12.146255493164062 sec\n",
            "TypeError: Failed to fetch\n",
            "Time for epoch 90 is 17.16747784614563 sec\n",
            "Time for epoch 91 is 12.202227115631104 sec\n",
            "Time for epoch 92 is 12.25670599937439 sec\n",
            "Time for epoch 93 is 12.179054021835327 sec\n",
            "Time for epoch 94 is 12.163156032562256 sec\n",
            "TypeError: Failed to fetch\n",
            "Time for epoch 95 is 17.117668390274048 sec\n",
            "Time for epoch 96 is 12.246340990066528 sec\n",
            "Time for epoch 97 is 12.137501001358032 sec\n",
            "Time for epoch 98 is 12.152796745300293 sec\n",
            "Time for epoch 99 is 12.199113845825195 sec\n",
            "TypeError: Failed to fetch\n",
            "Time for epoch 100 is 17.192829847335815 sec\n",
            "Time for epoch 101 is 12.252761363983154 sec\n",
            "Time for epoch 102 is 12.222023487091064 sec\n",
            "Time for epoch 103 is 12.189743280410767 sec\n",
            "Time for epoch 104 is 12.182804107666016 sec\n",
            "TypeError: Failed to fetch\n",
            "Time for epoch 105 is 17.15966010093689 sec\n",
            "Time for epoch 106 is 12.239157915115356 sec\n",
            "Time for epoch 107 is 12.112785816192627 sec\n",
            "Time for epoch 108 is 12.143759965896606 sec\n",
            "Time for epoch 109 is 12.206588983535767 sec\n",
            "TypeError: Failed to fetch\n",
            "Time for epoch 110 is 17.217570304870605 sec\n",
            "Time for epoch 111 is 12.219947338104248 sec\n",
            "Time for epoch 112 is 12.154206991195679 sec\n",
            "Time for epoch 113 is 12.154306411743164 sec\n",
            "Time for epoch 114 is 12.180632591247559 sec\n",
            "TypeError: Failed to fetch\n",
            "Time for epoch 115 is 17.173528909683228 sec\n",
            "Time for epoch 116 is 12.275572299957275 sec\n",
            "Time for epoch 117 is 12.187660932540894 sec\n",
            "Time for epoch 118 is 12.164158582687378 sec\n",
            "Time for epoch 119 is 12.13643765449524 sec\n",
            "TypeError: Failed to fetch\n",
            "Time for epoch 120 is 17.108073234558105 sec\n",
            "Time for epoch 121 is 12.229318141937256 sec\n",
            "Time for epoch 122 is 12.182953596115112 sec\n",
            "Time for epoch 123 is 12.16795802116394 sec\n",
            "Time for epoch 124 is 12.236345052719116 sec\n",
            "TypeError: Failed to fetch\n",
            "Time for epoch 125 is 17.51325225830078 sec\n",
            "Time for epoch 126 is 12.210715055465698 sec\n",
            "Time for epoch 127 is 12.184622049331665 sec\n",
            "Time for epoch 128 is 12.225347518920898 sec\n",
            "Time for epoch 129 is 12.154470205307007 sec\n",
            "TypeError: Failed to fetch\n",
            "Time for epoch 130 is 17.151500701904297 sec\n",
            "Time for epoch 131 is 12.279232740402222 sec\n",
            "Time for epoch 132 is 12.202375411987305 sec\n",
            "Time for epoch 133 is 12.215617656707764 sec\n",
            "Time for epoch 134 is 12.324522733688354 sec\n",
            "TypeError: Failed to fetch\n",
            "Time for epoch 135 is 17.243855237960815 sec\n",
            "Time for epoch 136 is 12.114083290100098 sec\n",
            "Time for epoch 137 is 12.134925127029419 sec\n",
            "Time for epoch 138 is 12.17835807800293 sec\n",
            "Time for epoch 139 is 12.036818981170654 sec\n",
            "TypeError: Failed to fetch\n",
            "Time for epoch 140 is 16.633644580841064 sec\n",
            "Time for epoch 141 is 12.312649011611938 sec\n",
            "Time for epoch 142 is 12.16185212135315 sec\n",
            "Time for epoch 143 is 12.13039255142212 sec\n",
            "Time for epoch 144 is 12.198889017105103 sec\n",
            "TypeError: Failed to fetch\n",
            "Time for epoch 145 is 18.718928337097168 sec\n",
            "Time for epoch 146 is 12.139655828475952 sec\n",
            "Time for epoch 147 is 12.146064519882202 sec\n",
            "Time for epoch 148 is 12.243141889572144 sec\n",
            "Time for epoch 149 is 12.210973024368286 sec\n",
            "TypeError: Failed to fetch\n",
            "Time for epoch 150 is 17.29619860649109 sec\n",
            "Time for epoch 151 is 12.196159601211548 sec\n",
            "Time for epoch 152 is 12.173283815383911 sec\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}