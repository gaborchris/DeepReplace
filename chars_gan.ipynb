{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "chars_gan",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gaborchris/DeepReplace/blob/master/chars_gan.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hOuYg9rkmc1b",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "884c9eb4-b0ee-4a76-90bb-79d8d23d7770"
      },
      "source": [
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "\n",
        "try:\n",
        "  from google.colab import files\n",
        "except Exception:\n",
        "  pass\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "import glob\n",
        "import imageio\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import PIL\n",
        "from tensorflow.keras import layers\n",
        "import time\n",
        "import pathlib"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mF40fEZi4hb-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 64\n",
        "NOISE_DIM = 100\n",
        "\n",
        "num_to_char = {}\n",
        "alphabet = 'abcdefghijklmnopqrstuvwxyz'\n",
        "for i in range(0, 10):\n",
        "    num_to_char[i] = str(i)\n",
        "for i in range(0, 26):\n",
        "    num_to_char[i+10] = alphabet[i].upper()\n",
        "for i in range(0, 26):\n",
        "    num_to_char[i+10+26] = alphabet[i].lower()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zAS3PZw_4pIc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_generator_model(n_classes=10):\n",
        "    # Create class embedding channel\n",
        "    input_label = tf.keras.layers.Input(shape=(1,))\n",
        "    label_embedding = tf.keras.layers.Embedding(n_classes, 50)(input_label)\n",
        "    upscaling = tf.keras.layers.Dense(7*7*1)(label_embedding)\n",
        "    upscaling = tf.keras.layers.Reshape((7, 7, 1))(upscaling)\n",
        "\n",
        "    # create seed encoding network\n",
        "    seed_input = tf.keras.layers.Input(shape=(NOISE_DIM,))\n",
        "    seed_fc = tf.keras.layers.Dense(7*7*256, use_bias=False)(seed_input)\n",
        "    seed_fc = tf.keras.layers.BatchNormalization()(seed_fc)\n",
        "    seed_fc = tf.keras.layers.LeakyReLU()(seed_fc)\n",
        "    seed_fc = tf.keras.layers.Reshape((7, 7, 256))(seed_fc)\n",
        "\n",
        "    # merge embedding with seed encoder\n",
        "    merge = tf.keras.layers.Concatenate()([seed_fc, upscaling])\n",
        "    assert tuple(merge.shape) == (None, 7, 7, 256+1)\n",
        "\n",
        "    x = layers.Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', use_bias=False)(merge)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.LeakyReLU()(x)\n",
        "    assert tuple(x.shape) == (None, 7, 7, 128)\n",
        "\n",
        "    x = layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.LeakyReLU()(x)\n",
        "    assert tuple(x.shape) == (None, 14, 14, 64)\n",
        "\n",
        "    # TODO tanh function with output between [-1, 1]\n",
        "    output = layers.Conv2DTranspose(3, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='sigmoid')(x)\n",
        "    model = tf.keras.Model([seed_input, input_label], output)\n",
        "    assert model.output_shape == (None, 28, 28, 3)\n",
        "\n",
        "    return model\n",
        "\n",
        "def make_discriminator_model(n_classes=10):\n",
        "    # Create a class embedding\n",
        "    input_label = tf.keras.layers.Input(shape=(1,))\n",
        "    label_embedding = tf.keras.layers.Embedding(n_classes, 50)(input_label)\n",
        "    upscaling = tf.keras.layers.Dense(28*28)(label_embedding)\n",
        "    upscaling = tf.keras.layers.Reshape((28, 28, 1))(upscaling)\n",
        "\n",
        "    # merge image with class embedding\n",
        "    input_image = tf.keras.layers.Input(shape=(28, 28, 3))\n",
        "    merge = tf.keras.layers.Concatenate()([input_image, upscaling])\n",
        "\n",
        "    # define classification architecture\n",
        "    x = tf.keras.layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same')(merge)\n",
        "    x = tf.keras.layers.LeakyReLU()(x)\n",
        "    x = tf.keras.layers.Dropout(0.3)(x)\n",
        "\n",
        "    x = layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same')(x)\n",
        "    x = layers.LeakyReLU()(x)\n",
        "    x = layers.Dropout(0.3)(x)\n",
        "\n",
        "    x = layers.Flatten()(x)\n",
        "    output = layers.Dense(1)(x)\n",
        "    model = tf.keras.Model([input_image, input_label], output)\n",
        "\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_V1zofMn40y0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "def discriminator_loss(real_output, fake_output):\n",
        "    cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
        "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
        "    total_loss = real_loss + fake_loss\n",
        "    return total_loss\n",
        "\n",
        "\n",
        "def generator_loss(predictions):\n",
        "    cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "    return cross_entropy(tf.ones_like(predictions), predictions)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Z3WdIEg4ZCs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_and_save_images(model, epoch, test_input, test_labels):\n",
        "    predictions = model([test_input, test_labels], training=False)\n",
        "\n",
        "    for i in range(predictions.shape[0]):\n",
        "        plt.subplot(4, 4, i + 1)\n",
        "        plt.imshow(predictions[i, :, :, :])\n",
        "        # TODO figure out how to upsample mean 0 and unit variance\n",
        "        # plt.imshow(predictions[i, :, :, 0] * 127.5 + 127.5, cmap='gray')\n",
        "        plt.xticks([])\n",
        "        plt.yticks([])\n",
        "        plt.xlabel(num_to_char[test_labels[i][0]])\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))\n",
        "    plt.close()\n",
        "    try:\n",
        "      files.download('image_at_epoch_{:04d}.png'.format(epoch))\n",
        "    except Exception:\n",
        "      pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sOW2jrDmnNv7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d3a9e61a-eca7-4a01-d1bc-f26ce5af40b2"
      },
      "source": [
        "# Get ground truth data\n",
        "data_dir = tf.keras.utils.get_file('English',\n",
        "                                    origin='http://www.ee.surrey.ac.uk/CVSSP/demos/chars74k/EnglishImg.tgz',\n",
        "                                    untar=True, extract=True)\n",
        "data_dir = pathlib.Path(data_dir)\n",
        "image_path = os.path.join(data_dir, \"Img/GoodImg/Bmp\")\n",
        "\n",
        "# TODO mean 0 and unit variance\n",
        "# image_generator = tf.keras.preprocessing.image.ImageDataGenerator(featurewise_center=True,\n",
        "#                                                                   featurewise_std_normalization=True)\n",
        "image_generator = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
        "image_ground_truth = image_generator.flow_from_directory(image_path, target_size=(28, 28),\n",
        "                                                          batch_size=BATCH_SIZE,\n",
        "                                                          class_mode='sparse')\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 7705 images belonging to 62 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PmtYEq344QHP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define Model\n",
        "num_classes = 62\n",
        "\n",
        "generator = make_generator_model(n_classes=num_classes)\n",
        "generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
        "discriminator = make_discriminator_model(n_classes=num_classes)\n",
        "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
        "\n",
        "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
        "                                  discriminator_optimizer=discriminator_optimizer,\n",
        "                                  generator=generator,\n",
        "                                  discriminator=discriminator)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CVVyZ1Sb4TO9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Setup repeated predictions\n",
        "num_examples_to_generate = 16\n",
        "seed = tf.random.normal([num_examples_to_generate, NOISE_DIM])\n",
        "seed_labels = np.random.randint(0, num_classes, num_examples_to_generate).reshape((-1, 1))\n",
        "fakes = generator([seed, seed_labels], training=False)\n",
        "generate_and_save_images(generator, 0, seed, seed_labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zPyic9uYo5kD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define training procedure\n",
        "@tf.function\n",
        "def train_step(images, ground_truth_labels):\n",
        "    noise = tf.random.normal([BATCH_SIZE, NOISE_DIM])\n",
        "    random_labels = np.random.randint(0, num_classes, BATCH_SIZE).reshape((-1, 1))\n",
        "\n",
        "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "        fakes = generator([noise, random_labels], training=True)\n",
        "        ground_truth_preds = discriminator([images, ground_truth_labels], training=True)\n",
        "        fake_preds = discriminator([fakes, random_labels], training=True)\n",
        "\n",
        "        gen_loss = generator_loss(fake_preds)\n",
        "        disc_loss = discriminator_loss(real_output=ground_truth_preds, fake_output=fake_preds)\n",
        "\n",
        "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
        "\n",
        "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
        "\n",
        "def train(dataset, epochs, ckpt_prefix):\n",
        "    print(\"Starting training\")\n",
        "    for epoch in range(epochs):\n",
        "        start = time.time()\n",
        "        i = 0\n",
        "        for (image_batch, labels_batch) in dataset:\n",
        "            train_step(image_batch, labels_batch)\n",
        "            i += 1\n",
        "            if i > len(dataset):\n",
        "              break\n",
        "\n",
        "        if (epoch + 1) % 5 == 0:\n",
        "            generate_and_save_images(generator, epoch+1, seed, seed_labels)\n",
        "            checkpoint.save(file_prefix=ckpt_prefix)\n",
        "        print('Time for epoch {} is {} sec'.format(epoch+1, time.time()-start))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qbrs4IFm7xzm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "55708729-5def-426f-8b6c-090864446d35"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ml85TFUa4-Qh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "checkpoint_dir = '/content/drive/My Drive/char_gan_ckpts/'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qLbSUSv19QRB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        },
        "outputId": "a022fe2e-e78a-4ca6-ce5c-5f0cb7254e48"
      },
      "source": [
        "status = checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))\n",
        "train(image_ground_truth, epochs=1000, ckpt_prefix=checkpoint_prefix)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting training\n",
            "Time for epoch 1 is 9.334131717681885 sec\n",
            "Time for epoch 2 is 5.750824451446533 sec\n",
            "Time for epoch 3 is 5.749228239059448 sec\n",
            "Time for epoch 4 is 5.806707859039307 sec\n",
            "Time for epoch 5 is 7.739721059799194 sec\n",
            "Time for epoch 6 is 5.892318248748779 sec\n",
            "Time for epoch 7 is 5.872906923294067 sec\n",
            "Time for epoch 8 is 5.870932579040527 sec\n",
            "Time for epoch 9 is 5.875095844268799 sec\n",
            "Time for epoch 10 is 7.317830324172974 sec\n",
            "Time for epoch 11 is 5.771472930908203 sec\n",
            "Time for epoch 12 is 5.825550079345703 sec\n",
            "Time for epoch 13 is 5.834111928939819 sec\n",
            "Time for epoch 14 is 5.737351894378662 sec\n",
            "Time for epoch 15 is 7.27737832069397 sec\n",
            "Time for epoch 16 is 5.729223728179932 sec\n",
            "Time for epoch 17 is 5.789766550064087 sec\n",
            "Time for epoch 18 is 5.803072214126587 sec\n",
            "Time for epoch 19 is 5.764939785003662 sec\n",
            "Time for epoch 20 is 7.77762508392334 sec\n",
            "Time for epoch 21 is 5.813733339309692 sec\n",
            "Time for epoch 22 is 5.834491968154907 sec\n",
            "Time for epoch 23 is 5.699938535690308 sec\n",
            "Time for epoch 24 is 5.7342894077301025 sec\n",
            "Time for epoch 25 is 7.435553789138794 sec\n",
            "Time for epoch 26 is 5.781312942504883 sec\n",
            "Time for epoch 27 is 5.739834547042847 sec\n",
            "Time for epoch 28 is 5.6962010860443115 sec\n",
            "Time for epoch 29 is 5.865351438522339 sec\n",
            "Time for epoch 30 is 7.410799503326416 sec\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pa5aa3YP_CyN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}